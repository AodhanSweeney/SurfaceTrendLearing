{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import glob\n",
    "import random\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import shapely.geometry as sgeom\n",
    "from shapely.ops import unary_union\n",
    "from shapely.prepared import prep\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import PolarTestingTrainingSplit_CV\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Get names of models in which we are testing on\n",
    "path_to_data = '/home/disk/pna2/aodhan/SurfaceTrendLearning/PoChedleyEtAl2022/TASmaps/*_TrendMaps.nc'\n",
    "ModelNames = [i[70:-16] for i in glob.glob(path_to_data)]\n",
    "\n",
    "# Get observational data\n",
    "observational_trends = glob.glob('/home/disk/p/aodhan/SurfaceTrendLearing/PolarApplication/TASObsTrends/*.npy')\n",
    "observational_trend_maps = [np.load(observational_trends[i]) for i in range(0,len(observational_trends))]\n",
    "latitudes = np.linspace(-88.75,88.75,72)\n",
    "weights = np.cos(np.deg2rad(latitudes)) # these will be used to weight predictors\n",
    "observational_trend_maps_weighted = np.multiply(observational_trend_maps, weights[np.newaxis,:,np.newaxis])\n",
    "observational_trend_maps_reshaped = np.reshape(observational_trend_maps_weighted, (3, 72*144))\n",
    "\n",
    "# Create Custom Color Map\n",
    "colors = np.array([(22,98,248), (48,141,250), (71,172,251), (100,201,252), (129,222,253),(162,240,254), (215,249,253), (255,255,255), \n",
    "                   (255,255,255), (255,249,217), (247,236,155), (254,221,128), (254,202,100), (255,173,71), (252,142,42), (255,101,15)])/255\n",
    "custom_cmap = LinearSegmentedColormap.from_list('cmap', colors)\n",
    "\n",
    "# Do CV train-test-split \n",
    "TrainingPredictorData, TrainingTargetData, TestingPredictorData, TestingTargetData, TestingTotalTrend = PolarTestingTrainingSplit_CV.training_testing_split(path_to_data)\n",
    "test_model_data = TestingPredictorData[0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10] r = 0.45 sqrt(MSE) = 0.038\n",
      "[20, 10] r = 0.64 sqrt(MSE) = 0.034\n",
      "[10, 20] r = 0.49 sqrt(MSE) = 0.047\n",
      "[5, 10] r = 0.57 sqrt(MSE) = 0.036\n",
      "[10, 5] r = 0.37 sqrt(MSE) = 0.087\n",
      "[10, 10, 20] r = 0.56 sqrt(MSE) = 0.040\n",
      "[10, 20, 10] r = 0.53 sqrt(MSE) = 0.037\n",
      "[20, 10, 10] r = 0.66 sqrt(MSE) = 0.027\n",
      "[10, 20, 20] r = 0.60 sqrt(MSE) = 0.032\n",
      "[20, 20, 20] r = 0.63 sqrt(MSE) = 0.033\n",
      "[20, 20, 10] r = 0.49 sqrt(MSE) = 0.043\n",
      "[20, 10, 20] r = 0.59 sqrt(MSE) = 0.035\n",
      "[10, 10, 10] r = 0.67 sqrt(MSE) = 0.029\n",
      "[10, 10, 10, 10] r = 0.65 sqrt(MSE) = 0.027\n",
      "[10, 20, 20, 10] r = 0.73 sqrt(MSE) = 0.024\n",
      "[20, 10, 10, 10] r = 0.66 sqrt(MSE) = 0.029\n",
      "[10, 10, 10, 20] r = 0.66 sqrt(MSE) = 0.030\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy import stats\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "layer_sizes = [[10,10], [20,10], [10,20], [5,10], [10,5],[10,10,20], [10,20,10], [20,10,10], [10,20,20], [20,20,20], [20,20,10], [20,10,20], [10,10,10], [10,10,10,10], [10,20,20,10], [20,10,10,10], [10,10,10,20]]\n",
    "for layer_size in layer_sizes:\n",
    "    # iterate over all CV folds (there should be eqaul number of CV folds as models)\n",
    "    predictions = []\n",
    "    validations = []\n",
    "    gistemp_predictions = []\n",
    "    era5_predictions = []\n",
    "    hadcrut_predictions = []\n",
    "\n",
    "    for model_idx in range(len(ModelNames)):\n",
    "        \n",
    "        # Reshape target and predictor data for model\n",
    "        TrainingTargetDataShape = np.shape(TrainingTargetData[model_idx])\n",
    "        TestinTargetDataShape = np.shape(TestingTargetData[model_idx])\n",
    "        TrainingTargetDataReshaped = np.reshape(TrainingTargetData[model_idx], (TrainingTargetDataShape[0], TrainingTargetDataShape[1]*TrainingTargetDataShape[2]))\n",
    "        TestingTargetDataReshaped = np.reshape(TestingTargetData[model_idx], (TestinTargetDataShape[0], TestinTargetDataShape[1]*TestinTargetDataShape[2]))\n",
    "\n",
    "        # Model Design\n",
    "        if len(layer_size) == 2:\n",
    "            MLmodel =  MLPRegressor(hidden_layer_sizes=(layer_size[0], layer_size[1]), activation='relu', solver='adam', random_state=42)\n",
    "        elif len(layer_size) == 3:\n",
    "            MLmodel =  MLPRegressor(hidden_layer_sizes=(layer_size[0], layer_size[1], layer_size[2]), activation='relu', solver='adam', random_state=42)\n",
    "        elif len(layer_size) == 4:\n",
    "            MLmodel =  MLPRegressor(hidden_layer_sizes=(layer_size[0], layer_size[1], layer_size[2], layer_size[3]), activation='relu', solver='adam', random_state=42)\n",
    "        \n",
    "        # Train model\n",
    "        TrainingTargetDataReshaped = TrainingTargetDataReshaped[:,0]\n",
    "        pls_model = MLmodel.fit(TrainingPredictorData[model_idx], TrainingTargetDataReshaped)\n",
    "\n",
    "        # Predict using trained model\n",
    "        Y_pred = MLmodel.predict(TestingPredictorData[model_idx])\n",
    "        \n",
    "        # Apply trained model to observations\n",
    "        Y_pred_Gistemp = MLmodel.predict(observational_trend_maps_reshaped[0].reshape(1, -1))\n",
    "        Y_pred_ERA5 = MLmodel.predict(observational_trend_maps_reshaped[1].reshape(1, -1))\n",
    "        Y_pred_HadCrut = MLmodel.predict(observational_trend_maps_reshaped[2].reshape(1, -1))\n",
    "        \n",
    "        # Save output for plotting\n",
    "        gistemp_predictions.append(Y_pred_Gistemp)\n",
    "        era5_predictions.append(Y_pred_ERA5)\n",
    "        hadcrut_predictions.append(Y_pred_HadCrut)\n",
    "\n",
    "        validations.append(TestingTargetDataReshaped[:,0])\n",
    "        predictions.append(Y_pred)\n",
    "    \n",
    "    vals = list(np.concatenate(validations).flat)\n",
    "    preds = list(np.concatenate(predictions).flat)\n",
    "    allsimulation_r = stats.pearsonr(vals, preds)[0]\n",
    "    sqrt_mse = np.sqrt(np.nanmean((np.array(vals) - np.array(preds))**2))\n",
    "\n",
    "    print(layer_size, 'r = ' + str(allsimulation_r)[:4] + ' sqrt(MSE) = ' + str(sqrt_mse)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 10] r = 0.21 sqrt(MSE) = 0.075\n",
      "[20, 10, 5] r = 0.41 sqrt(MSE) = 0.047\n",
      "[10, 20, 20, 10] r = 0.73 sqrt(MSE) = 0.024\n",
      "[30, 20, 10] r = 0.54 sqrt(MSE) = 0.043\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [[100,10], [20,10,5],  [10,20,20,10], [30,20,10]]\n",
    "for layer_size in layer_sizes:\n",
    "    # iterate over all CV folds (there should be eqaul number of CV folds as models)\n",
    "    predictions = []\n",
    "    validations = []\n",
    "    gistemp_predictions = []\n",
    "    era5_predictions = []\n",
    "    hadcrut_predictions = []\n",
    "\n",
    "    for model_idx in range(len(ModelNames)):\n",
    "        \n",
    "        # Reshape target and predictor data for model\n",
    "        TrainingTargetDataShape = np.shape(TrainingTargetData[model_idx])\n",
    "        TestinTargetDataShape = np.shape(TestingTargetData[model_idx])\n",
    "        TrainingTargetDataReshaped = np.reshape(TrainingTargetData[model_idx], (TrainingTargetDataShape[0], TrainingTargetDataShape[1]*TrainingTargetDataShape[2]))\n",
    "        TestingTargetDataReshaped = np.reshape(TestingTargetData[model_idx], (TestinTargetDataShape[0], TestinTargetDataShape[1]*TestinTargetDataShape[2]))\n",
    "\n",
    "        # Model Design\n",
    "        if len(layer_size) == 2:\n",
    "            MLmodel =  MLPRegressor(hidden_layer_sizes=(layer_size[0], layer_size[1]), activation='relu', solver='adam', random_state=42)\n",
    "        elif len(layer_size) == 3:\n",
    "            MLmodel =  MLPRegressor(hidden_layer_sizes=(layer_size[0], layer_size[1], layer_size[2]), activation='relu', solver='adam', random_state=42)\n",
    "        elif len(layer_size) == 4:\n",
    "            MLmodel =  MLPRegressor(hidden_layer_sizes=(layer_size[0], layer_size[1], layer_size[2], layer_size[3]), activation='relu', solver='adam', random_state=42)\n",
    "        \n",
    "        # Train model\n",
    "        TrainingTargetDataReshaped = TrainingTargetDataReshaped[:,0]\n",
    "        pls_model = MLmodel.fit(TrainingPredictorData[model_idx], TrainingTargetDataReshaped)\n",
    "\n",
    "        # Predict using trained model\n",
    "        Y_pred = MLmodel.predict(TestingPredictorData[model_idx])\n",
    "        \n",
    "        # Apply trained model to observations\n",
    "        Y_pred_Gistemp = MLmodel.predict(observational_trend_maps_reshaped[0].reshape(1, -1))\n",
    "        Y_pred_ERA5 = MLmodel.predict(observational_trend_maps_reshaped[1].reshape(1, -1))\n",
    "        Y_pred_HadCrut = MLmodel.predict(observational_trend_maps_reshaped[2].reshape(1, -1))\n",
    "        \n",
    "        # Save output for plotting\n",
    "        gistemp_predictions.append(Y_pred_Gistemp)\n",
    "        era5_predictions.append(Y_pred_ERA5)\n",
    "        hadcrut_predictions.append(Y_pred_HadCrut)\n",
    "\n",
    "        validations.append(TestingTargetDataReshaped[:,0])\n",
    "        predictions.append(Y_pred)\n",
    "    \n",
    "    vals = list(np.concatenate(validations).flat)\n",
    "    preds = list(np.concatenate(predictions).flat)\n",
    "    allsimulation_r = stats.pearsonr(vals, preds)[0]\n",
    "    sqrt_mse = np.sqrt(np.nanmean((np.array(vals) - np.array(preds))**2))\n",
    "\n",
    "    print(layer_size, 'r = ' + str(allsimulation_r)[:4] + ' sqrt(MSE) = ' + str(sqrt_mse)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 20, 10] r = 0.73 sqrt(MSE) = 0.024\n",
      "[30, 20, 10] r = 0.69 sqrt(MSE) = 0.027\n",
      "[30, 20, 10] r = 0.59 sqrt(MSE) = 0.031\n",
      "[30, 20, 10] r = 0.64 sqrt(MSE) = 0.030\n",
      "[30, 20, 10] r = 2.62 sqrt(MSE) = 0.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/p/aodhan/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 20, 10] r = 0.00 sqrt(MSE) = 0.032\n",
      "[30, 20, 10] r = 3.97 sqrt(MSE) = 0.032\n",
      "[30, 20, 10] r = -1.5 sqrt(MSE) = 0.032\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.0001, 0.001, 0.01, 0.1, 1,10]\n",
    "for alpha_ in alphas:\n",
    "    # iterate over all CV folds (there should be eqaul number of CV folds as models)\n",
    "    predictions = []\n",
    "    validations = []\n",
    "    gistemp_predictions = []\n",
    "    era5_predictions = []\n",
    "    hadcrut_predictions = []\n",
    "\n",
    "    for model_idx in range(len(ModelNames)):\n",
    "        \n",
    "        # Reshape target and predictor data for model\n",
    "        TrainingTargetDataShape = np.shape(TrainingTargetData[model_idx])\n",
    "        TestinTargetDataShape = np.shape(TestingTargetData[model_idx])\n",
    "        TrainingTargetDataReshaped = np.reshape(TrainingTargetData[model_idx], (TrainingTargetDataShape[0], TrainingTargetDataShape[1]*TrainingTargetDataShape[2]))\n",
    "        TestingTargetDataReshaped = np.reshape(TestingTargetData[model_idx], (TestinTargetDataShape[0], TestinTargetDataShape[1]*TestinTargetDataShape[2]))\n",
    "\n",
    "        # Model Design\n",
    "        MLmodel =  MLPRegressor(hidden_layer_sizes=(10,20,20,10), activation='relu', solver='adam', alpha=alpha_, random_state=42)\n",
    "        \n",
    "        # Train model\n",
    "        TrainingTargetDataReshaped = TrainingTargetDataReshaped[:,0]\n",
    "        pls_model = MLmodel.fit(TrainingPredictorData[model_idx], TrainingTargetDataReshaped)\n",
    "\n",
    "        # Predict using trained model\n",
    "        Y_pred = MLmodel.predict(TestingPredictorData[model_idx])\n",
    "        \n",
    "        # Apply trained model to observations\n",
    "        Y_pred_Gistemp = MLmodel.predict(observational_trend_maps_reshaped[0].reshape(1, -1))\n",
    "        Y_pred_ERA5 = MLmodel.predict(observational_trend_maps_reshaped[1].reshape(1, -1))\n",
    "        Y_pred_HadCrut = MLmodel.predict(observational_trend_maps_reshaped[2].reshape(1, -1))\n",
    "        \n",
    "        # Save output for plotting\n",
    "        gistemp_predictions.append(Y_pred_Gistemp)\n",
    "        era5_predictions.append(Y_pred_ERA5)\n",
    "        hadcrut_predictions.append(Y_pred_HadCrut)\n",
    "\n",
    "        validations.append(TestingTargetDataReshaped[:,0])\n",
    "        predictions.append(Y_pred)\n",
    "    \n",
    "    vals = list(np.concatenate(validations).flat)\n",
    "    preds = list(np.concatenate(predictions).flat)\n",
    "    allsimulation_r = stats.pearsonr(vals, preds)[0]\n",
    "    sqrt_mse = np.sqrt(np.nanmean((np.array(vals) - np.array(preds))**2))\n",
    "\n",
    "    print(alpha_, 'r = ' + str(allsimulation_r)[:4] + ' sqrt(MSE) = ' + str(sqrt_mse)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 r = 0.67 sqrt(MSE) = 0.029\n",
      "0.001 r = 0.54 sqrt(MSE) = 0.041\n",
      "0.01 r = 0.63 sqrt(MSE) = 0.035\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3603611/2301127195.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mTrainingTargetDataReshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainingTargetDataReshaped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mpls_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingPredictorData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingTargetDataReshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Predict using trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \"\"\"\n\u001b[0;32m--> 752\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_pass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, y, incremental, reset)\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1596\u001b[0;31m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1597\u001b[0m         )\n\u001b[1;32m   1598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy import stats\n",
    "\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1, 1,10]\n",
    "for alpha_ in alphas:\n",
    "    # iterate over all CV folds (there should be eqaul number of CV folds as models)\n",
    "    predictions = []\n",
    "    validations = []\n",
    "    gistemp_predictions = []\n",
    "    era5_predictions = []\n",
    "    hadcrut_predictions = []\n",
    "\n",
    "    for model_idx in range(len(ModelNames)):\n",
    "        \n",
    "        # Reshape target and predictor data for model\n",
    "        TrainingTargetDataShape = np.shape(TrainingTargetData[model_idx])\n",
    "        TestinTargetDataShape = np.shape(TestingTargetData[model_idx])\n",
    "        TrainingTargetDataReshaped = np.reshape(TrainingTargetData[model_idx], (TrainingTargetDataShape[0], TrainingTargetDataShape[1]*TrainingTargetDataShape[2]))\n",
    "        TestingTargetDataReshaped = np.reshape(TestingTargetData[model_idx], (TestinTargetDataShape[0], TestinTargetDataShape[1]*TestinTargetDataShape[2]))\n",
    "\n",
    "        # Model Design\n",
    "        MLmodel =  MLPRegressor(hidden_layer_sizes=(10,10,10), activation='relu', solver='adam', alpha=alpha_, random_state=42)\n",
    "        \n",
    "        # Train model\n",
    "        TrainingTargetDataReshaped = TrainingTargetDataReshaped[:,0]\n",
    "        pls_model = MLmodel.fit(TrainingPredictorData[model_idx], TrainingTargetDataReshaped)\n",
    "\n",
    "        # Predict using trained model\n",
    "        Y_pred = MLmodel.predict(TestingPredictorData[model_idx])\n",
    "        \n",
    "        # Apply trained model to observations\n",
    "        Y_pred_Gistemp = MLmodel.predict(observational_trend_maps_reshaped[0].reshape(1, -1))\n",
    "        Y_pred_ERA5 = MLmodel.predict(observational_trend_maps_reshaped[1].reshape(1, -1))\n",
    "        Y_pred_HadCrut = MLmodel.predict(observational_trend_maps_reshaped[2].reshape(1, -1))\n",
    "        \n",
    "        # Save output for plotting\n",
    "        gistemp_predictions.append(Y_pred_Gistemp)\n",
    "        era5_predictions.append(Y_pred_ERA5)\n",
    "        hadcrut_predictions.append(Y_pred_HadCrut)\n",
    "\n",
    "        validations.append(TestingTargetDataReshaped[:,0])\n",
    "        predictions.append(Y_pred)\n",
    "    \n",
    "    vals = list(np.concatenate(validations).flat)\n",
    "    preds = list(np.concatenate(predictions).flat)\n",
    "    allsimulation_r = stats.pearsonr(vals, preds)[0]\n",
    "    sqrt_mse = np.sqrt(np.nanmean((np.array(vals) - np.array(preds))**2))\n",
    "\n",
    "    print(alpha_, 'r = ' + str(allsimulation_r)[:4] + ' sqrt(MSE) = ' + str(sqrt_mse)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 20, 20, 10] r = 0.60 sqrt(MSE) = 0.033\n",
      "[6, 20, 20, 10] r = 0.64 sqrt(MSE) = 0.032\n",
      "[14, 20, 20, 10] r = 0.63 sqrt(MSE) = 0.033\n",
      "[18, 20, 20, 10] r = 0.67 sqrt(MSE) = 0.028\n",
      "[10, 12, 20, 10] r = 0.59 sqrt(MSE) = 0.030\n",
      "[10, 16, 20, 10] r = 0.63 sqrt(MSE) = 0.030\n",
      "[10, 24, 20, 10] r = 0.58 sqrt(MSE) = 0.038\n",
      "[10, 28, 20, 10] r = 0.60 sqrt(MSE) = 0.034\n",
      "[10, 20, 12, 10] r = 0.65 sqrt(MSE) = 0.029\n",
      "[10, 20, 16, 10] r = 0.64 sqrt(MSE) = 0.030\n",
      "[10, 20, 24, 10] r = 0.65 sqrt(MSE) = 0.032\n",
      "[10, 20, 28, 10] r = 0.60 sqrt(MSE) = 0.034\n",
      "[10, 20, 20, 2] r = 0.53 sqrt(MSE) = 0.039\n",
      "[10, 20, 20, 6] r = 0.63 sqrt(MSE) = 0.026\n",
      "[10, 20, 20, 14] r = 0.66 sqrt(MSE) = 0.029\n",
      "[10, 20, 20, 18] r = 0.66 sqrt(MSE) = 0.029\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy import stats\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "layer_base = [10,20,20,10]\n",
    "layer_sizes = []\n",
    "for idx in range(4):\n",
    "    for add in [-8,-4,4,8]:\n",
    "        adjusted_layer = layer_base.copy()\n",
    "        adjusted_layer_value = layer_base[idx] + add\n",
    "        adjusted_layer[idx] = adjusted_layer_value\n",
    "        #print(adjusted_layer)\n",
    "        layer_sizes.append(adjusted_layer)\n",
    "for layer_size in layer_sizes:\n",
    "    # iterate over all CV folds (there should be eqaul number of CV folds as models)\n",
    "    predictions = []\n",
    "    validations = []\n",
    "    gistemp_predictions = []\n",
    "    era5_predictions = []\n",
    "    hadcrut_predictions = []\n",
    "\n",
    "    for model_idx in range(len(ModelNames)):\n",
    "        \n",
    "        # Reshape target and predictor data for model\n",
    "        TrainingTargetDataShape = np.shape(TrainingTargetData[model_idx])\n",
    "        TestinTargetDataShape = np.shape(TestingTargetData[model_idx])\n",
    "        TrainingTargetDataReshaped = np.reshape(TrainingTargetData[model_idx], (TrainingTargetDataShape[0], TrainingTargetDataShape[1]*TrainingTargetDataShape[2]))\n",
    "        TestingTargetDataReshaped = np.reshape(TestingTargetData[model_idx], (TestinTargetDataShape[0], TestinTargetDataShape[1]*TestinTargetDataShape[2]))\n",
    "\n",
    "        # Model Design\n",
    "        if len(layer_size) == 2:\n",
    "            MLmodel =  MLPRegressor(hidden_layer_sizes=(layer_size[0], layer_size[1]), activation='relu', solver='adam', random_state=42)\n",
    "        elif len(layer_size) == 3:\n",
    "            MLmodel =  MLPRegressor(hidden_layer_sizes=(layer_size[0], layer_size[1], layer_size[2]), activation='relu', solver='adam', random_state=42)\n",
    "        elif len(layer_size) == 4:\n",
    "            MLmodel =  MLPRegressor(hidden_layer_sizes=(layer_size[0], layer_size[1], layer_size[2], layer_size[3]), activation='relu', solver='adam', random_state=42)\n",
    "        \n",
    "        # Train model\n",
    "        TrainingTargetDataReshaped = TrainingTargetDataReshaped[:,0]\n",
    "        pls_model = MLmodel.fit(TrainingPredictorData[model_idx], TrainingTargetDataReshaped)\n",
    "\n",
    "        # Predict using trained model\n",
    "        Y_pred = MLmodel.predict(TestingPredictorData[model_idx])\n",
    "        \n",
    "        # Apply trained model to observations\n",
    "        Y_pred_Gistemp = MLmodel.predict(observational_trend_maps_reshaped[0].reshape(1, -1))\n",
    "        Y_pred_ERA5 = MLmodel.predict(observational_trend_maps_reshaped[1].reshape(1, -1))\n",
    "        Y_pred_HadCrut = MLmodel.predict(observational_trend_maps_reshaped[2].reshape(1, -1))\n",
    "        \n",
    "        # Save output for plotting\n",
    "        gistemp_predictions.append(Y_pred_Gistemp)\n",
    "        era5_predictions.append(Y_pred_ERA5)\n",
    "        hadcrut_predictions.append(Y_pred_HadCrut)\n",
    "\n",
    "        validations.append(TestingTargetDataReshaped[:,0])\n",
    "        predictions.append(Y_pred)\n",
    "    \n",
    "    vals = list(np.concatenate(validations).flat)\n",
    "    preds = list(np.concatenate(predictions).flat)\n",
    "    allsimulation_r = stats.pearsonr(vals, preds)[0]\n",
    "    sqrt_mse = np.sqrt(np.nanmean((np.array(vals) - np.array(preds))**2))\n",
    "\n",
    "    print(layer_size, 'r = ' + str(allsimulation_r)[:4] + ' sqrt(MSE) = ' + str(sqrt_mse)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5e-05 r = 0.72 sqrt(MSE) = 0.026\n",
      "7.5e-05 r = 0.72 sqrt(MSE) = 0.025\n",
      "0.0001 r = 0.73 sqrt(MSE) = 0.024\n",
      "0.000125 r = 0.69 sqrt(MSE) = 0.027\n",
      "0.00015 r = 0.65 sqrt(MSE) = 0.029\n",
      "0.00025 r = 0.68 sqrt(MSE) = 0.027\n",
      "0.0005 r = 0.71 sqrt(MSE) = 0.026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy import stats\n",
    "\n",
    "alphas = [0.00005, 0.000075, 0.0001, 0.000125, 0.00015, 0.00025,.0005]\n",
    "for alpha_ in alphas:\n",
    "    # iterate over all CV folds (there should be eqaul number of CV folds as models)\n",
    "    predictions = []\n",
    "    validations = []\n",
    "    gistemp_predictions = []\n",
    "    era5_predictions = []\n",
    "    hadcrut_predictions = []\n",
    "\n",
    "    for model_idx in range(len(ModelNames)):\n",
    "        \n",
    "        # Reshape target and predictor data for model\n",
    "        TrainingTargetDataShape = np.shape(TrainingTargetData[model_idx])\n",
    "        TestinTargetDataShape = np.shape(TestingTargetData[model_idx])\n",
    "        TrainingTargetDataReshaped = np.reshape(TrainingTargetData[model_idx], (TrainingTargetDataShape[0], TrainingTargetDataShape[1]*TrainingTargetDataShape[2]))\n",
    "        TestingTargetDataReshaped = np.reshape(TestingTargetData[model_idx], (TestinTargetDataShape[0], TestinTargetDataShape[1]*TestinTargetDataShape[2]))\n",
    "\n",
    "        # Model Design\n",
    "        MLmodel =  MLPRegressor(hidden_layer_sizes=(10,20,20,10), activation='relu', solver='adam', alpha=alpha_, random_state=42)\n",
    "        \n",
    "        # Train model\n",
    "        TrainingTargetDataReshaped = TrainingTargetDataReshaped[:,0]\n",
    "        pls_model = MLmodel.fit(TrainingPredictorData[model_idx], TrainingTargetDataReshaped)\n",
    "\n",
    "        # Predict using trained model\n",
    "        Y_pred = MLmodel.predict(TestingPredictorData[model_idx])\n",
    "        \n",
    "        # Apply trained model to observations\n",
    "        Y_pred_Gistemp = MLmodel.predict(observational_trend_maps_reshaped[0].reshape(1, -1))\n",
    "        Y_pred_ERA5 = MLmodel.predict(observational_trend_maps_reshaped[1].reshape(1, -1))\n",
    "        Y_pred_HadCrut = MLmodel.predict(observational_trend_maps_reshaped[2].reshape(1, -1))\n",
    "        \n",
    "        # Save output for plotting\n",
    "        gistemp_predictions.append(Y_pred_Gistemp)\n",
    "        era5_predictions.append(Y_pred_ERA5)\n",
    "        hadcrut_predictions.append(Y_pred_HadCrut)\n",
    "\n",
    "        validations.append(TestingTargetDataReshaped[:,0])\n",
    "        predictions.append(Y_pred)\n",
    "    \n",
    "    vals = list(np.concatenate(validations).flat)\n",
    "    preds = list(np.concatenate(predictions).flat)\n",
    "    allsimulation_r = stats.pearsonr(vals, preds)[0]\n",
    "    sqrt_mse = np.sqrt(np.nanmean((np.array(vals) - np.array(preds))**2))\n",
    "\n",
    "    print(alpha_, 'r = ' + str(allsimulation_r)[:4] + ' sqrt(MSE) = ' + str(sqrt_mse)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.5e-05 r = 0.70 sqrt(MSE) = 0.027\n",
      "9.5e-05 r = 0.66 sqrt(MSE) = 0.027\n",
      "0.000105 r = 0.68 sqrt(MSE) = 0.026\n",
      "0.000115 r = 0.67 sqrt(MSE) = 0.027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy import stats\n",
    "\n",
    "alphas = [0.000085, 0.000095, 0.000105, 0.000115]\n",
    "for alpha_ in alphas:\n",
    "    # iterate over all CV folds (there should be eqaul number of CV folds as models)\n",
    "    predictions = []\n",
    "    validations = []\n",
    "    gistemp_predictions = []\n",
    "    era5_predictions = []\n",
    "    hadcrut_predictions = []\n",
    "\n",
    "    for model_idx in range(len(ModelNames)):\n",
    "        \n",
    "        # Reshape target and predictor data for model\n",
    "        TrainingTargetDataShape = np.shape(TrainingTargetData[model_idx])\n",
    "        TestinTargetDataShape = np.shape(TestingTargetData[model_idx])\n",
    "        TrainingTargetDataReshaped = np.reshape(TrainingTargetData[model_idx], (TrainingTargetDataShape[0], TrainingTargetDataShape[1]*TrainingTargetDataShape[2]))\n",
    "        TestingTargetDataReshaped = np.reshape(TestingTargetData[model_idx], (TestinTargetDataShape[0], TestinTargetDataShape[1]*TestinTargetDataShape[2]))\n",
    "\n",
    "        # Model Design\n",
    "        MLmodel =  MLPRegressor(hidden_layer_sizes=(10,20,20,10), activation='relu', solver='adam', alpha=alpha_, random_state=42)\n",
    "        \n",
    "        # Train model\n",
    "        TrainingTargetDataReshaped = TrainingTargetDataReshaped[:,0]\n",
    "        pls_model = MLmodel.fit(TrainingPredictorData[model_idx], TrainingTargetDataReshaped)\n",
    "\n",
    "        # Predict using trained model\n",
    "        Y_pred = MLmodel.predict(TestingPredictorData[model_idx])\n",
    "        \n",
    "        # Apply trained model to observations\n",
    "        Y_pred_Gistemp = MLmodel.predict(observational_trend_maps_reshaped[0].reshape(1, -1))\n",
    "        Y_pred_ERA5 = MLmodel.predict(observational_trend_maps_reshaped[1].reshape(1, -1))\n",
    "        Y_pred_HadCrut = MLmodel.predict(observational_trend_maps_reshaped[2].reshape(1, -1))\n",
    "        \n",
    "        # Save output for plotting\n",
    "        gistemp_predictions.append(Y_pred_Gistemp)\n",
    "        era5_predictions.append(Y_pred_ERA5)\n",
    "        hadcrut_predictions.append(Y_pred_HadCrut)\n",
    "\n",
    "        validations.append(TestingTargetDataReshaped[:,0])\n",
    "        predictions.append(Y_pred)\n",
    "    \n",
    "    vals = list(np.concatenate(validations).flat)\n",
    "    preds = list(np.concatenate(predictions).flat)\n",
    "    allsimulation_r = stats.pearsonr(vals, preds)[0]\n",
    "    sqrt_mse = np.sqrt(np.nanmean((np.array(vals) - np.array(preds))**2))\n",
    "\n",
    "    print(alpha_, 'r = ' + str(allsimulation_r)[:4] + ' sqrt(MSE) = ' + str(sqrt_mse)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00025 r = 0.68 sqrt(MSE) = 0.027\n",
      "0.00035 r = 0.66 sqrt(MSE) = 0.027\n",
      "0.00045 r = 0.69 sqrt(MSE) = 0.027\n",
      "0.00055 r = 0.62 sqrt(MSE) = 0.030\n",
      "0.00065 r = 0.65 sqrt(MSE) = 0.029\n",
      "0.00075 r = 0.72 sqrt(MSE) = 0.025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy import stats\n",
    "\n",
    "alphas = [0.00025,.00035, .00045, .00055, .00065, .00075]\n",
    "for alpha_ in alphas:\n",
    "    # iterate over all CV folds (there should be eqaul number of CV folds as models)\n",
    "    predictions = []\n",
    "    validations = []\n",
    "    gistemp_predictions = []\n",
    "    era5_predictions = []\n",
    "    hadcrut_predictions = []\n",
    "\n",
    "    for model_idx in range(len(ModelNames)):\n",
    "        \n",
    "        # Reshape target and predictor data for model\n",
    "        TrainingTargetDataShape = np.shape(TrainingTargetData[model_idx])\n",
    "        TestinTargetDataShape = np.shape(TestingTargetData[model_idx])\n",
    "        TrainingTargetDataReshaped = np.reshape(TrainingTargetData[model_idx], (TrainingTargetDataShape[0], TrainingTargetDataShape[1]*TrainingTargetDataShape[2]))\n",
    "        TestingTargetDataReshaped = np.reshape(TestingTargetData[model_idx], (TestinTargetDataShape[0], TestinTargetDataShape[1]*TestinTargetDataShape[2]))\n",
    "\n",
    "        # Model Design\n",
    "        MLmodel =  MLPRegressor(hidden_layer_sizes=(10,20,20,10), activation='relu', solver='adam', alpha=alpha_, random_state=42)\n",
    "        \n",
    "        # Train model\n",
    "        TrainingTargetDataReshaped = TrainingTargetDataReshaped[:,0]\n",
    "        pls_model = MLmodel.fit(TrainingPredictorData[model_idx], TrainingTargetDataReshaped)\n",
    "\n",
    "        # Predict using trained model\n",
    "        Y_pred = MLmodel.predict(TestingPredictorData[model_idx])\n",
    "        \n",
    "        # Apply trained model to observations\n",
    "        Y_pred_Gistemp = MLmodel.predict(observational_trend_maps_reshaped[0].reshape(1, -1))\n",
    "        Y_pred_ERA5 = MLmodel.predict(observational_trend_maps_reshaped[1].reshape(1, -1))\n",
    "        Y_pred_HadCrut = MLmodel.predict(observational_trend_maps_reshaped[2].reshape(1, -1))\n",
    "        \n",
    "        # Save output for plotting\n",
    "        gistemp_predictions.append(Y_pred_Gistemp)\n",
    "        era5_predictions.append(Y_pred_ERA5)\n",
    "        hadcrut_predictions.append(Y_pred_HadCrut)\n",
    "\n",
    "        validations.append(TestingTargetDataReshaped[:,0])\n",
    "        predictions.append(Y_pred)\n",
    "    \n",
    "    vals = list(np.concatenate(validations).flat)\n",
    "    preds = list(np.concatenate(predictions).flat)\n",
    "    allsimulation_r = stats.pearsonr(vals, preds)[0]\n",
    "    sqrt_mse = np.sqrt(np.nanmean((np.array(vals) - np.array(preds))**2))\n",
    "\n",
    "    print(alpha_, 'r = ' + str(allsimulation_r)[:4] + ' sqrt(MSE) = ' + str(sqrt_mse)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af835c7fa3f1d66f76e7463e82810696e6cb13c598b94db10ac6143493e4a761"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
