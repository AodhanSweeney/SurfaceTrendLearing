{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPSL-CM6A-LR r8i1p1f1\n",
      "IPSL-CM6A-LR r2i1p1f1\n",
      "IPSL-CM6A-LR r30i1p1f1\n",
      "IPSL-CM6A-LR r29i1p1f1\n",
      "IPSL-CM6A-LR r3i1p1f1\n",
      "IPSL-CM6A-LR r6i1p1f1\n",
      "IPSL-CM6A-LR r27i1p1f1\n",
      "IPSL-CM6A-LR r7i1p1f1\n",
      "IPSL-CM6A-LR r9i1p1f1\n",
      "IPSL-CM6A-LR r26i1p1f1\n",
      "IPSL-CM6A-LR r20i1p1f1\n",
      "IPSL-CM6A-LR r25i1p1f1\n",
      "IPSL-CM6A-LR r24i1p1f1\n",
      "IPSL-CM6A-LR r31i1p1f1\n",
      "IPSL-CM6A-LR r22i1p1f1\n",
      "IPSL-CM6A-LR r21i1p1f1\n",
      "IPSL-CM6A-LR r23i1p1f1\n",
      "IPSL-CM6A-LR r19i1p1f1\n",
      "IPSL-CM6A-LR r18i1p1f1\n",
      "IPSL-CM6A-LR r11i1p1f1\n",
      "IPSL-CM6A-LR r12i1p1f1\n",
      "IPSL-CM6A-LR r17i1p1f1\n",
      "IPSL-CM6A-LR r16i1p1f1\n",
      "IPSL-CM6A-LR r1i1p1f1\n",
      "IPSL-CM6A-LR r5i1p1f1\n",
      "IPSL-CM6A-LR r4i1p1f1\n",
      "IPSL-CM6A-LR r28i1p1f1\n",
      "IPSL-CM6A-LR r14i1p1f1\n",
      "IPSL-CM6A-LR r10i1p1f1\n",
      "IPSL-CM6A-LR r15i1p1f1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import zipfile\n",
    "import glob\n",
    "import netCDF4 as nc\n",
    "import xesmf as xe\n",
    "from scipy import stats\n",
    "\n",
    "def trend_finder(timeseries_maps):\n",
    "    \"\"\"\n",
    "    Find decadal trends at each lat and lon point. \n",
    "    \"\"\"\n",
    "    shape_of_maps = np.shape(timeseries_maps)\n",
    "    # must be adjusted based on len of time used for trends\n",
    "    years = np.linspace(0,3.5,36)\n",
    "    trend_map = []\n",
    "    for lat in range(0, shape_of_maps[1]):\n",
    "        lat_line = []\n",
    "        for lon in range(0, shape_of_maps[2]):\n",
    "            timeseries = timeseries_maps[:,lat,lon]\n",
    "            trend = stats.linregress(x=years, y=timeseries)[0] # in K/dec\n",
    "            lat_line.append(trend)\n",
    "        trend_map.append(lat_line)\n",
    "    return(np.array(trend_map))\n",
    "    \n",
    "            \n",
    "# load path to CMIP 6 data\n",
    "path_to_CMIP6_data = '/home/disk/pna2/aodhan/CMIP6/historical_monthly_tas_google/*'\n",
    "model_paths = glob.glob(path_to_CMIP6_data)\n",
    "\n",
    "# here we select the start times of trends, this can be changed\n",
    "start_times = np.arange(1854,1980,5)\n",
    "\n",
    "# for each model...\n",
    "for model in model_paths:\n",
    "    realizations = glob.glob(model + '/*')\n",
    "\n",
    "    # create data dictionary\n",
    "    model_trends = []\n",
    "    \n",
    "    # for each realization...\n",
    "    simulation_names = []\n",
    "    for ensemble_member in realizations:\n",
    "        simulation = xr.open_dataset(ensemble_member)\n",
    "        model_name = simulation.source_id\n",
    "        simulation_name = simulation.variant_label\n",
    "        simulation_names.append(simulation_name)\n",
    "        print(model_name, simulation_name)\n",
    "\n",
    "         # CMIP6 models must be regridded, below we define input and output grids\n",
    "        latitudes = simulation.lat.values\n",
    "        longitudes = simulation.lon.values\n",
    "        InputGrid = {\"lon\": longitudes, \"lat\": latitudes}\n",
    "        OutputGrid = {\"lon\": np.arange(1.25, 358.751, 2.5), \"lat\": np.arange(-88.75, 88.751, 2.5)}\n",
    "        regridder = xe.Regridder(InputGrid, OutputGrid, \"bilinear\")\n",
    "        \n",
    "        # create lists for where to append data\n",
    "        all_timeperiod_trends = []\n",
    "        time_keys = []\n",
    "\n",
    "        # find time slices for just winter\n",
    "        for i in start_times:\n",
    "            start_date = str(i) + '-01'\n",
    "            end_date = str(i+35) + '-12'\n",
    "            time_key = str(i) + '-' + str(i+35)\n",
    "\n",
    "            # find correct time period of data\n",
    "            time_slice_data = simulation.sel(time=slice(start_date, end_date))\n",
    "            data_array = time_slice_data.tas.values\n",
    "\n",
    "            # find trends for each of the time periods\n",
    "            shape_of_data_array = np.shape(data_array)\n",
    "            data_calendar = np.reshape(data_array, (36, 12, shape_of_data_array[1], shape_of_data_array[2]))\n",
    "            season_calendar = [data_calendar[:,10],data_calendar[:,11], data_calendar[:,0], \n",
    "                               data_calendar[:,1], data_calendar[:,2]]\n",
    "            timeseries_map = np.nanmean(season_calendar, axis=0)\n",
    "            trend_map = trend_finder(timeseries_map)\n",
    "            trend_map_2p5x2p5 = regridder(trend_map)\n",
    "            all_timeperiod_trends.append(trend_map_2p5x2p5)\n",
    "            time_keys.append(time_key)\n",
    "        \n",
    "        # append all timeperiod trends \n",
    "        model_trends.append(all_timeperiod_trends)\n",
    "\n",
    "    \n",
    "\n",
    "    # Timeperiod data will be dumped into NetCDF files\n",
    "    fileName = path_to_CMIP6_data + '/trendmap' + model.replace(\"-\", \"_\") + '_TAS_NDJFM_TrendMaps.nc'\n",
    "\n",
    "    # Create netcdf file with dimensions\n",
    "    ds = nc.Dataset(fileName, 'w', format='NETCDF4')\n",
    "    ensemble_member = ds.createDimension('ensemble_member', len(simulation_names))\n",
    "    TrendTimePeriod = ds.createDimension('TrendTimePeriod', 26) # 26 timeperiods\n",
    "    Lat = ds.createDimension('Lat', 72)\n",
    "    Lon = ds.createDimension('Lon', 144)\n",
    "\n",
    "    # Add variables to dimensions\n",
    "    ensemble_member = ds.createVariable('ensemble_member', str, ('ensemble_member',))\n",
    "    TrendTimePeriod = ds.createVariable('TrendTimePeriod', str, ('TrendTimePeriod',))\n",
    "    Lat = ds.createVariable('Lat', 'f4', ('Lat',))\n",
    "    Lon = ds.createVariable('Lon', 'f4', ('Lon',))\n",
    "    Ts_trends = ds.createVariable('ts_trend', 'f4', ('ensemble_member', 'TrendTimePeriod', 'Lat', 'Lon'))\n",
    "\n",
    "    # Assing values to variables\n",
    "    ensemble_member[:] = simulation_names\n",
    "    TrendTimePeriod[:] = time_keys\n",
    "    Lat[:] = np.arange(-88.75, 88.751, 2.5)\n",
    "    Lon[:] = np.arange(1.25, 358.751, 2.5)\n",
    "    Ts_trends[:] = model_trends\n",
    "\n",
    "    ds.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(start_times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af835c7fa3f1d66f76e7463e82810696e6cb13c598b94db10ac6143493e4a761"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
