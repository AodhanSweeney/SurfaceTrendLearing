{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC-Earth3 r9i1p1f1 9\n",
      "EC-Earth3 r11i1p1f1 11\n",
      "EC-Earth3 r13i1p1f1 13\n",
      "EC-Earth3 r15i1p1f1 15\n",
      "EC-Earth3 r6i1p1f1 6\n",
      "EC-Earth3 r1i1p1f1 1\n",
      "EC-Earth3 r20i1p1f1 20\n",
      "skipping:  r118i1p1f1\n",
      "skipping:  r127i1p1f1\n",
      "skipping:  r126i1p1f1\n",
      "skipping:  r119i1p1f1\n",
      "skipping:  r122i1p1f1\n",
      "skipping:  r120i1p1f1\n",
      "skipping:  r121i1p1f1\n",
      "skipping:  r106i1p1f1\n",
      "skipping:  r149i1p1f1\n",
      "skipping:  r105i1p1f1\n",
      "skipping:  r103i1p1f1\n",
      "skipping:  r102i1p1f1\n",
      "skipping:  r150i1p1f1\n",
      "skipping:  r104i1p1f1\n",
      "skipping:  r101i1p1f1\n",
      "skipping:  r128i1p1f1\n",
      "skipping:  r129i1p1f1\n",
      "skipping:  r130i1p1f1\n",
      "skipping:  r133i1p1f1\n",
      "skipping:  r134i1p1f1\n",
      "skipping:  r136i1p1f1\n",
      "skipping:  r137i1p1f1\n",
      "skipping:  r145i1p1f1\n",
      "skipping:  r138i1p1f1\n",
      "skipping:  r131i1p1f1\n",
      "skipping:  r132i1p1f1\n",
      "skipping:  r135i1p1f1\n",
      "skipping:  r109i1p1f1\n",
      "skipping:  r108i1p1f1\n",
      "skipping:  r107i1p1f1\n",
      "skipping:  r117i1p1f1\n",
      "skipping:  r116i1p1f1\n",
      "skipping:  r115i1p1f1\n",
      "skipping:  r124i1p1f1\n",
      "skipping:  r123i1p1f1\n",
      "skipping:  r125i1p1f1\n",
      "skipping:  r111i1p1f1\n",
      "skipping:  r110i1p1f1\n",
      "skipping:  r139i1p1f1\n",
      "skipping:  r140i1p1f1\n",
      "skipping:  r144i1p1f1\n",
      "skipping:  r146i1p1f1\n",
      "skipping:  r148i1p1f1\n",
      "skipping:  r147i1p1f1\n",
      "skipping:  r112i1p1f1\n",
      "skipping:  r113i1p1f1\n",
      "skipping:  r114i1p1f1\n",
      "skipping:  r142i1p1f1\n",
      "skipping:  r143i1p1f1\n",
      "skipping:  r141i1p1f1\n",
      "EC-Earth3 r4i1p1f1 4\n",
      "EC-Earth3 r3i1p1f1 3\n",
      "EC-Earth3 r2i1p1f1 2\n",
      "EC-Earth3 r7i1p1f1 7\n",
      "EC-Earth3 r14i1p1f1 14\n",
      "EC-Earth3 r10i1p1f1 10\n",
      "EC-Earth3 r12i1p1f1 12\n",
      "EC-Earth3 r16i1p1f1 16\n",
      "EC-Earth3 r17i1p1f1 17\n",
      "EC-Earth3 r18i1p1f1 18\n",
      "EC-Earth3 r21i1p1f1 21\n",
      "EC-Earth3 r19i1p1f1 19\n",
      "EC-Earth3 r22i1p1f1 22\n",
      "EC-Earth3 r23i1p1f1 23\n",
      "EC-Earth3 r25i1p1f1 25\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import zipfile\n",
    "import glob\n",
    "import netCDF4 as nc\n",
    "import xesmf as xe\n",
    "from scipy import stats\n",
    "\n",
    "def trend_finder(timeseries_maps):\n",
    "    \"\"\"\n",
    "    Find decadal trends at each lat and lon point. \n",
    "    \"\"\"\n",
    "    shape_of_maps = np.shape(timeseries_maps)\n",
    "    # must be adjusted based on len of time used for trends\n",
    "    years = np.linspace(0,3.5,36)\n",
    "    trend_map = []\n",
    "    for lat in range(0, shape_of_maps[1]):\n",
    "        lat_line = []\n",
    "        for lon in range(0, shape_of_maps[2]):\n",
    "            timeseries = timeseries_maps[:,lat,lon]\n",
    "            trend = stats.linregress(x=years, y=timeseries)[0] # in K/dec\n",
    "            lat_line.append(trend)\n",
    "        trend_map.append(lat_line)\n",
    "    return(np.array(trend_map))\n",
    "            \n",
    "# load path to CMIP 6 data\n",
    "path_to_CMIP6_data = '/home/disk/pna2/aodhan/CMIP6/historical_monthly_psl_google/*'\n",
    "model_paths = glob.glob(path_to_CMIP6_data)\n",
    "\n",
    "# here we select the start times of trends, this can be changed\n",
    "start_times = np.arange(1854,1980,5)\n",
    "\n",
    "# for each model...\n",
    "for model in model_paths[-2:-1]: # the -1 is because the last \"model\" is the directory /trendmap where data is stored\n",
    "    realizations = glob.glob(model + '/*')\n",
    "\n",
    "    # create data dictionary\n",
    "    model_trends = []\n",
    "    \n",
    "    # for each realization...\n",
    "    simulation_index = []\n",
    "    simulation_count = 1\n",
    "    for ensemble_member in realizations:\n",
    "\n",
    "        # if we run into problems with given simulation, skip it\n",
    "        simulation = xr.open_dataset(ensemble_member)\n",
    "        model_name = simulation.source_id\n",
    "        simulation_name = simulation.variant_label\n",
    "        simulation_number = int(simulation_name.split('i')[0][1:])\n",
    "\n",
    "        # CMIP6 models must be regridded, below we define input and output grids\n",
    "        latitudes = simulation.lat.values\n",
    "        longitudes = simulation.lon.values\n",
    "        InputGrid = {\"lon\": longitudes, \"lat\": latitudes}\n",
    "        OutputGrid = {\"lon\": np.arange(1.25, 358.751, 2.5), \"lat\": np.arange(-88.75, 88.751, 2.5)}\n",
    "        regridder = xe.Regridder(InputGrid, OutputGrid, \"bilinear\")\n",
    "        \n",
    "        # create lists for where to append data\n",
    "        all_timeperiod_trends = []\n",
    "        time_keys = []\n",
    "        \n",
    "        try:\n",
    "            # find time slices for just winter\n",
    "            for i in start_times:\n",
    "                start_date = str(i) + '-01'\n",
    "                end_date = str(i+35) + '-12'\n",
    "\n",
    "                # find correct time period of data\n",
    "                time_slice_data = simulation.sel(time=slice(start_date, end_date))\n",
    "                data_array = time_slice_data.psl.values\n",
    "\n",
    "                # find trends for each of the time periods\n",
    "                shape_of_data_array = np.shape(data_array)\n",
    "                data_calendar = np.reshape(data_array, (36, 12, shape_of_data_array[1], shape_of_data_array[2]))\n",
    "                season_calendar = [data_calendar[:,10],data_calendar[:,11], data_calendar[:,0], \n",
    "                                data_calendar[:,1], data_calendar[:,2]]\n",
    "                timeseries_map = np.nanmean(season_calendar, axis=0)\n",
    "                trend_map = trend_finder(timeseries_map)\n",
    "                trend_map_2p5x2p5 = regridder(trend_map)\n",
    "                all_timeperiod_trends.append(trend_map_2p5x2p5)\n",
    "                time_keys.append(i)\n",
    "\n",
    "            # if you can successfully create trend maps, then add this index as a simulation used\n",
    "            simulation_index.append(simulation_number)\n",
    "            print(model_name, simulation_name, simulation_number)\n",
    "        except:\n",
    "            print('skipping: ', simulation_name)\n",
    "            continue\n",
    "    \n",
    "        # append all timeperiod trends \n",
    "        model_trends.append(all_timeperiod_trends)\n",
    "\n",
    "    # Timeperiod data will be dumped into NetCDF files\n",
    "    fileName = path_to_CMIP6_data[:-2] + '/trendmap/' + model_name.replace(\"-\", \"_\") + '_PSL_NDJFM_TrendMaps.nc'\n",
    "\n",
    "    # Create netcdf file with dimensions\n",
    "    ds = nc.Dataset(fileName, 'w', format='NETCDF4')\n",
    "    ensemble_member = ds.createDimension('ensemble_member', len(simulation_index))\n",
    "    TrendTimePeriod = ds.createDimension('TrendTimePeriod', len(time_keys)) # 26 timeperiods\n",
    "    Lat = ds.createDimension('Lat', 72)\n",
    "    Lon = ds.createDimension('Lon', 144)\n",
    "\n",
    "    # Add variables to dimensions\n",
    "    ensemble_member = ds.createVariable('ensemble_member', int, ('ensemble_member',))\n",
    "    TrendTimePeriod = ds.createVariable('TrendTimePeriod', int, ('TrendTimePeriod',))\n",
    "    Lat = ds.createVariable('Lat', 'f4', ('Lat',))\n",
    "    Lon = ds.createVariable('Lon', 'f4', ('Lon',))\n",
    "    Ts_trends = ds.createVariable('ts_trend', 'f4', ('ensemble_member', 'TrendTimePeriod', 'Lat', 'Lon'))\n",
    "\n",
    "    # Assing values to variables\n",
    "    ensemble_member[:] = simulation_index\n",
    "    TrendTimePeriod[:] = time_keys\n",
    "    Lat[:] = np.arange(-88.75, 88.751, 2.5)\n",
    "    Lon[:] = np.arange(1.25, 358.751, 2.5)\n",
    "    Ts_trends[:] = model_trends\n",
    "\n",
    "    ds.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC-Earth3 r9i1p1f1 9\n",
      "EC-Earth3 r11i1p1f1 11\n",
      "EC-Earth3 r13i1p1f1 13\n",
      "EC-Earth3 r15i1p1f1 15\n",
      "EC-Earth3 r6i1p1f1 6\n",
      "EC-Earth3 r1i1p1f1 1\n",
      "EC-Earth3 r119i1p1f1 119\n",
      "skipping:  r119i1p1f1\n",
      "EC-Earth3 r118i1p1f1 118\n",
      "skipping:  r118i1p1f1\n",
      "EC-Earth3 r117i1p1f1 117\n",
      "skipping:  r117i1p1f1\n",
      "EC-Earth3 r127i1p1f1 127\n",
      "skipping:  r127i1p1f1\n",
      "EC-Earth3 r125i1p1f1 125\n",
      "skipping:  r125i1p1f1\n",
      "EC-Earth3 r126i1p1f1 126\n",
      "skipping:  r126i1p1f1\n",
      "EC-Earth3 r120i1p1f1 120\n",
      "skipping:  r120i1p1f1\n",
      "EC-Earth3 r121i1p1f1 121\n",
      "skipping:  r121i1p1f1\n",
      "EC-Earth3 r122i1p1f1 122\n",
      "skipping:  r122i1p1f1\n",
      "EC-Earth3 r148i1p1f1 148\n",
      "skipping:  r148i1p1f1\n",
      "EC-Earth3 r106i1p1f1 106\n",
      "skipping:  r106i1p1f1\n",
      "EC-Earth3 r149i1p1f1 149\n",
      "skipping:  r149i1p1f1\n",
      "EC-Earth3 r105i1p1f1 105\n",
      "skipping:  r105i1p1f1\n",
      "EC-Earth3 r103i1p1f1 103\n",
      "skipping:  r103i1p1f1\n",
      "EC-Earth3 r101i1p1f1 101\n",
      "skipping:  r101i1p1f1\n",
      "EC-Earth3 r150i1p1f1 150\n",
      "skipping:  r150i1p1f1\n",
      "EC-Earth3 r104i1p1f1 104\n",
      "skipping:  r104i1p1f1\n",
      "EC-Earth3 r102i1p1f1 102\n",
      "skipping:  r102i1p1f1\n",
      "EC-Earth3 r136i1p1f1 136\n",
      "skipping:  r136i1p1f1\n",
      "EC-Earth3 r129i1p1f1 129\n",
      "skipping:  r129i1p1f1\n",
      "EC-Earth3 r128i1p1f1 128\n",
      "skipping:  r128i1p1f1\n",
      "EC-Earth3 r130i1p1f1 130\n",
      "skipping:  r130i1p1f1\n",
      "EC-Earth3 r137i1p1f1 137\n",
      "skipping:  r137i1p1f1\n",
      "EC-Earth3 r131i1p1f1 131\n",
      "skipping:  r131i1p1f1\n",
      "EC-Earth3 r143i1p1f1 143\n",
      "skipping:  r143i1p1f1\n",
      "EC-Earth3 r145i1p1f1 145\n",
      "skipping:  r145i1p1f1\n",
      "EC-Earth3 r132i1p1f1 132\n",
      "skipping:  r132i1p1f1\n",
      "EC-Earth3 r133i1p1f1 133\n",
      "skipping:  r133i1p1f1\n",
      "EC-Earth3 r135i1p1f1 135\n",
      "skipping:  r135i1p1f1\n",
      "EC-Earth3 r134i1p1f1 134\n",
      "skipping:  r134i1p1f1\n",
      "EC-Earth3 r108i1p1f1 108\n",
      "skipping:  r108i1p1f1\n",
      "EC-Earth3 r109i1p1f1 109\n",
      "skipping:  r109i1p1f1\n",
      "EC-Earth3 r115i1p1f1 115\n",
      "skipping:  r115i1p1f1\n",
      "EC-Earth3 r107i1p1f1 107\n",
      "skipping:  r107i1p1f1\n",
      "EC-Earth3 r116i1p1f1 116\n",
      "skipping:  r116i1p1f1\n",
      "EC-Earth3 r124i1p1f1 124\n",
      "skipping:  r124i1p1f1\n",
      "EC-Earth3 r123i1p1f1 123\n",
      "skipping:  r123i1p1f1\n",
      "EC-Earth3 r111i1p1f1 111\n",
      "skipping:  r111i1p1f1\n",
      "EC-Earth3 r110i1p1f1 110\n",
      "skipping:  r110i1p1f1\n",
      "EC-Earth3 r138i1p1f1 138\n",
      "skipping:  r138i1p1f1\n",
      "EC-Earth3 r139i1p1f1 139\n",
      "skipping:  r139i1p1f1\n",
      "EC-Earth3 r140i1p1f1 140\n",
      "skipping:  r140i1p1f1\n",
      "EC-Earth3 r147i1p1f1 147\n",
      "skipping:  r147i1p1f1\n",
      "EC-Earth3 r144i1p1f1 144\n",
      "skipping:  r144i1p1f1\n",
      "EC-Earth3 r146i1p1f1 146\n",
      "skipping:  r146i1p1f1\n",
      "EC-Earth3 r114i1p1f1 114\n",
      "skipping:  r114i1p1f1\n",
      "EC-Earth3 r112i1p1f1 112\n",
      "skipping:  r112i1p1f1\n",
      "EC-Earth3 r113i1p1f1 113\n",
      "skipping:  r113i1p1f1\n",
      "EC-Earth3 r142i1p1f1 142\n",
      "skipping:  r142i1p1f1\n",
      "EC-Earth3 r141i1p1f1 141\n",
      "skipping:  r141i1p1f1\n",
      "EC-Earth3 r4i1p1f1 4\n",
      "EC-Earth3 r3i1p1f1 3\n",
      "EC-Earth3 r2i1p1f1 2\n",
      "EC-Earth3 r7i1p1f1 7\n",
      "EC-Earth3 r14i1p1f1 14\n",
      "EC-Earth3 r10i1p1f1 10\n",
      "EC-Earth3 r12i1p1f1 12\n",
      "EC-Earth3 r16i1p1f1 16\n",
      "EC-Earth3 r17i1p1f1 17\n",
      "EC-Earth3 r18i1p1f1 18\n",
      "EC-Earth3 r21i1p1f1 21\n",
      "EC-Earth3 r20i1p1f1 20\n",
      "EC-Earth3 r19i1p1f1 19\n",
      "EC-Earth3 r22i1p1f1 22\n",
      "EC-Earth3 r23i1p1f1 23\n",
      "EC-Earth3 r24i1p1f1 24\n",
      "EC-Earth3 r25i1p1f1 25\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: b'/home/disk/pna2/aodhan/CMIP6/historical_monthly_tas_google/trendmap/EC_Earth3_TAS_NDJFM_TrendMaps.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_192177/783221386.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# Create netcdf file with dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NETCDF4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mensemble_member\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ensemble_member'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulation_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mTrendTimePeriod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TrendTimePeriod'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 26 timeperiods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: b'/home/disk/pna2/aodhan/CMIP6/historical_monthly_tas_google/trendmap/EC_Earth3_TAS_NDJFM_TrendMaps.nc'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import zipfile\n",
    "import glob\n",
    "import netCDF4 as nc\n",
    "import xesmf as xe\n",
    "from scipy import stats\n",
    "\n",
    "def trend_finder(timeseries_maps):\n",
    "    \"\"\"\n",
    "    Find decadal trends at each lat and lon point. \n",
    "    \"\"\"\n",
    "    shape_of_maps = np.shape(timeseries_maps)\n",
    "    # must be adjusted based on len of time used for trends\n",
    "    years = np.linspace(0,3.5,36)\n",
    "    trend_map = []\n",
    "    for lat in range(0, shape_of_maps[1]):\n",
    "        lat_line = []\n",
    "        for lon in range(0, shape_of_maps[2]):\n",
    "            timeseries = timeseries_maps[:,lat,lon]\n",
    "            trend = stats.linregress(x=years, y=timeseries)[0] # in K/dec\n",
    "            lat_line.append(trend)\n",
    "        trend_map.append(lat_line)\n",
    "    return(np.array(trend_map))\n",
    "            \n",
    "# load path to CMIP 6 data\n",
    "path_to_CMIP6_data = '/home/disk/pna2/aodhan/CMIP6/historical_monthly_tas_google/*'\n",
    "model_paths = glob.glob(path_to_CMIP6_data)\n",
    "\n",
    "# here we select the start times of trends, this can be changed\n",
    "start_times = np.arange(1854,1980,5)\n",
    "\n",
    "# for each model...\n",
    "for model in model_paths[-2:-1]:\n",
    "    \n",
    "    realizations = glob.glob(model + '/*')\n",
    "\n",
    "    # create data dictionary\n",
    "    model_trends = []\n",
    "    \n",
    "    # for each realization...\n",
    "    simulation_index = []\n",
    "    for ensemble_member in realizations:\n",
    "        simulation = xr.open_dataset(ensemble_member)\n",
    "        model_name = simulation.source_id\n",
    "        simulation_name = simulation.variant_label\n",
    "        simulation_number = int(simulation_name.split('i')[0][1:])\n",
    "        print(model_name, simulation_name, simulation_number)\n",
    "\n",
    "         # CMIP6 models must be regridded, below we define input and output grids\n",
    "        latitudes = simulation.lat.values\n",
    "        longitudes = simulation.lon.values\n",
    "        InputGrid = {\"lon\": longitudes, \"lat\": latitudes}\n",
    "        OutputGrid = {\"lon\": np.arange(1.25, 358.751, 2.5), \"lat\": np.arange(-88.75, 88.751, 2.5)}\n",
    "        regridder = xe.Regridder(InputGrid, OutputGrid, \"bilinear\", periodic=True)\n",
    "        \n",
    "        # create lists for where to append data\n",
    "        all_timeperiod_trends = []\n",
    "        time_keys = []\n",
    "\n",
    "        try:\n",
    "            # find time slices for just winter\n",
    "            for i in start_times:\n",
    "                start_date = str(i) + '-01'\n",
    "                end_date = str(i+35) + '-12'\n",
    "\n",
    "                # find correct time period of data\n",
    "                time_slice_data = simulation.sel(time=slice(start_date, end_date))\n",
    "                data_array = time_slice_data.tas.values\n",
    "\n",
    "                # find trends for each of the time periods\n",
    "                shape_of_data_array = np.shape(data_array)\n",
    "                data_calendar = np.reshape(data_array, (36, 12, shape_of_data_array[1], shape_of_data_array[2]))\n",
    "                season_calendar = [data_calendar[:,10],data_calendar[:,11], data_calendar[:,0], \n",
    "                                data_calendar[:,1], data_calendar[:,2]]\n",
    "                timeseries_map = np.nanmean(season_calendar, axis=0)\n",
    "                trend_map = trend_finder(timeseries_map)\n",
    "                trend_map_2p5x2p5 = regridder(trend_map)\n",
    "                all_timeperiod_trends.append(trend_map_2p5x2p5)\n",
    "                time_keys.append(i)\n",
    "\n",
    "            # if you can successfully create trend maps, then add this index as a simulation used\n",
    "            simulation_index.append(simulation_number)\n",
    "        except:\n",
    "            print('skipping: ', simulation_name)\n",
    "            continue\n",
    "        \n",
    "        # append all timeperiod trends \n",
    "        model_trends.append(all_timeperiod_trends)\n",
    "\n",
    "    # Timeperiod data will be dumped into NetCDF files\n",
    "    fileName = path_to_CMIP6_data[:-2] + '/trendmap/' + model_name.replace(\"-\", \"_\") + '_TAS_NDJFM_TrendMaps.nc'\n",
    "\n",
    "    # Create netcdf file with dimensions\n",
    "    ds = nc.Dataset(fileName, 'w', format='NETCDF4')\n",
    "    ensemble_member = ds.createDimension('ensemble_member', len(simulation_index))\n",
    "    TrendTimePeriod = ds.createDimension('TrendTimePeriod', len(time_keys)) # 26 timeperiods\n",
    "    Lat = ds.createDimension('Lat', 72)\n",
    "    Lon = ds.createDimension('Lon', 144)\n",
    "\n",
    "    # Add variables to dimensions\n",
    "    ensemble_member = ds.createVariable('ensemble_member', int, ('ensemble_member',))\n",
    "    TrendTimePeriod = ds.createVariable('TrendTimePeriod', int, ('TrendTimePeriod',))\n",
    "    Lat = ds.createVariable('Lat', 'f4', ('Lat',))\n",
    "    Lon = ds.createVariable('Lon', 'f4', ('Lon',))\n",
    "    Ts_trends = ds.createVariable('ts_trend', 'f4', ('ensemble_member', 'TrendTimePeriod', 'Lat', 'Lon'))\n",
    "\n",
    "    # Assing values to variables\n",
    "    ensemble_member[:] = simulation_index\n",
    "    TrendTimePeriod[:] = time_keys\n",
    "    Lat[:] = np.arange(-88.75, 88.751, 2.5)\n",
    "    Lon[:] = np.arange(1.25, 358.751, 2.5)\n",
    "    Ts_trends[:] = model_trends\n",
    "\n",
    "    ds.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeperiod data will be dumped into NetCDF files\n",
    "fileName = path_to_CMIP6_data[:-2] + '/trendmap/' + model_name.replace(\"-\", \"_\") + '_TAS_NDJFM_TrendMaps.nc'\n",
    "\n",
    "# Create netcdf file with dimensions\n",
    "ds = nc.Dataset(fileName, 'w', format='NETCDF4')\n",
    "ensemble_member = ds.createDimension('ensemble_member', len(simulation_index))\n",
    "TrendTimePeriod = ds.createDimension('TrendTimePeriod', len(time_keys)) # 26 timeperiods\n",
    "Lat = ds.createDimension('Lat', 72)\n",
    "Lon = ds.createDimension('Lon', 144)\n",
    "\n",
    "# Add variables to dimensions\n",
    "ensemble_member = ds.createVariable('ensemble_member', int, ('ensemble_member',))\n",
    "TrendTimePeriod = ds.createVariable('TrendTimePeriod', int, ('TrendTimePeriod',))\n",
    "Lat = ds.createVariable('Lat', 'f4', ('Lat',))\n",
    "Lon = ds.createVariable('Lon', 'f4', ('Lon',))\n",
    "Ts_trends = ds.createVariable('ts_trend', 'f4', ('ensemble_member', 'TrendTimePeriod', 'Lat', 'Lon'))\n",
    "\n",
    "# Assing values to variables\n",
    "ensemble_member[:] = simulation_index\n",
    "TrendTimePeriod[:] = time_keys\n",
    "Lat[:] = np.arange(-88.75, 88.751, 2.5)\n",
    "Lon[:] = np.arange(1.25, 358.751, 2.5)\n",
    "Ts_trends[:] = model_trends\n",
    "\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af835c7fa3f1d66f76e7463e82810696e6cb13c598b94db10ac6143493e4a761"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
